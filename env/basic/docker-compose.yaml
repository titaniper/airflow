version: "3.7"

services:
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - airflow

  redis:
    image: redis:latest
    networks:
      - airflow

  airflow-init:
    image: apache/airflow:2.3.3
    entrypoint: /bin/bash
    command: >
      -c "
      airflow db init &&
      (airflow users create --role Admin --username admin --password admin --email admin@example.com --firstname Admin --lastname User ||
      echo 'Admin user already exists, skipping user creation.')
      "
    # command: -c "airflow db init && airflow users create --role Admin --username admin --password admin --email admin@example.com --firstname Admin --lastname User"
    # command: -c "airflow db init && airflow users create -r Admin -u admin -p admin -e admin@example.com -f Admin -l User"
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CORE__FERNET_KEY: 51hOOZ6FeVUbAKEYe1OOiWCRSjPI-n1f5QVFK6hg98M=
      AIRFLOW__WEBSERVER__SECRET_KEY: 51hOOZ6FeVUbAKEYe1OOiWCRSjPI-n1f5QVFK6hg98M=
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "true"
    networks:
      - airflow
    depends_on:
      - postgres
      - redis
  airflow-webserver:
    image: apache/airflow:2.3.3
    ports:
      - "21111:8080"
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CORE__FERNET_KEY: 51hOOZ6FeVUbAKEYe1OOiWCRSjPI-n1f5QVFK6hg98M=
      AIRFLOW__WEBSERVER__SECRET_KEY: 51hOOZ6FeVUbAKEYe1OOiWCRSjPI-n1f5QVFK6hg98M=
    volumes:
      - ./dags:/opt/airflow/dags
    networks:
      - airflow
    depends_on:
      - postgres
      - redis
      - airflow-init
  airflow-scheduler:
    image: apache/airflow:2.3.3
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CORE__FERNET_KEY: 51hOOZ6FeVUbAKEYe1OOiWCRSjPI-n1f5QVFK6hg98M=
      AIRFLOW__WEBSERVER__SECRET_KEY: 51hOOZ6FeVUbAKEYe1OOiWCRSjPI-n1f5QVFK6hg98M=
    volumes:
      - ./dags:/opt/airflow/dags
    networks:
      - airflow
    depends_on:
      - postgres
      - redis
      - airflow-init
  airflow-worker:
    image: apache/airflow:2.3.3
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CORE__FERNET_KEY: 51hOOZ6FeVUbAKEYe1OOiWCRSjPI-n1f5QVFK6hg98M=
      AIRFLOW__WEBSERVER__SECRET_KEY: 51hOOZ6FeVUbAKEYe1OOiWCRSjPI-n1f5QVFK6hg98M=
    volumes:
      - ./dags:/opt/airflow/dags
    networks:
      - airflow
    depends_on:
      - postgres
      - redis
      - airflow-init
volumes:
  postgres_data:

# 네트워크를 정의, Docker 컨테이너들이 같은 호스트 내에서 서로 통신할 수 있도록 합니다. bridge 네트워크는 컨테이너가 동일한 호스트에 있을 때 사용하는 기본 네트워크 모드로, 각 컨테이너는 동일한 네트워크 내에서 서로의 이름을 통해 접근할 수 있습니다.
networks:
  airflow:
    driver: bridge
